#Student_Engagement_Dectecting_System


 **目  录**

[第1章 作品概述	1](#_toc41432038)

[第2章 问题描述	1](#_toc41432039)

[第3章 技术方案	3](#_toc41432040)

[第4章 方案实现	4](#_toc41432041)

[第5章 测试分析	4](#_toc41432042)

[第6章 部署推广	5](#_toc41432043)

[第7章 作品总结	5](#_toc41432044)

[参考文献	5](#_toc41432045)




#  作品概述

【填写说明：重点介绍本作品的主题创意来源，产生背景，作品的用户群体、主要功能与特色、应用价值、推广前景等。如果有同类竞品，建议从多个维度对本作品与竞品进行比较】

由于COVID-19疫情的影响，线上教学的应用范围迅速扩张，许多新的大规模在线开放课程（MOOC）也相继出现。构建一个有效的在线学习环境需要考虑多个必要因素，例如对于在线课堂价值的评估标准，以及教师对于在线教学工具的需求。

构建有效在线学习环境的关键因素之一是控制学生在课堂上的参与度。虽然线上教学打破了地域限制、避免了直接接触，更好地适应了学生的生活和学习需求，但与传统线下课程相比，其面临着一个显著的问题：**缺乏面对面的互动和沟通。**在进行线下授课时，教师可以利用学生群体层面的情感反馈来放慢或修改授课的内容，但是在听讲人数较多的线上课堂中，老师很难像线下课程那样有效地获得反馈并控制学生的课堂参与度。尽管许多在线学习平台目前已经开展了对学生参与度形成性评价的研究，但似乎只有**对学生进行实时自动检测才是最合适的解决方案。**

此外，根据中华人民共和国教育部令第50号《学校保护规定》以及《国家智慧教育平台数字教育资源内容审核规范》，在线学习平台应重视保护学生隐私，并建立共享与公开的安全机制。**为了确保学生隐私的保护，参与度分类计算最好直接在学生的个人设备上进行**。这也意味着进行参与度分类计算的模型应该是轻量级的，以适用于低资源环境。

因此，本文的目的是开发一种**轻量级的，带有隐私保护功能的学生参与度分析系统**。该系统可以运行在低计算资源的环境下，并高效地帮助教师在线上教学过程中获取班级的参与度信息，提高线上教学效率。本文的主要贡献如下：

- **我们提出了一种全新的轻量级网络模型架构，**并采用权重交叉熵损失函数来训练该模型。通过增加对低样本类别的惩罚，我们有效地提高了网络模型的泛化性能。该模型在保持轻量化特点的同时，在实验中取得了竞争性的结果。
- **我们贡献了一个新的学习参与度数据集，填补了该领域的空白。**涉及到隐私权，该领域的大部分数据集都是非公开的。仅有的少量公开数据集普遍存在数据不平衡，标注不准确等多种问题。为了解决这个问题，我们采集了本校真实的在线课堂数据，并对这些数据进行了数据清洗与参与度分类，制作成了全新的学习参与度识别数据集**（下称ER Dataset）**。
- **我们设计了全新的技术框架**，**基于实时面部图像进行参与度预测。该技术框架是山东科技大学贾瑞生老师课题组的研究成果。**通过摄像头获取学生的面部信息后，每个学生的参与度都可以在移动设备上进行计算，然后将计算结果经过加密后发送到云端数据库，以保护学生的隐私。教师设备可以从云端数据库读取到班级的数据，并对其进行可视化分析（图1）。
![Aspose Words 114ca37a-2e51-44f2-8727-161185576537 001](https://github.com/Dengpc-FIRE/Student_Engagement_Dectecting_System/assets/115885750/c2b28285-80ab-4a3e-9ca3-185467041793)



# 问题描述

【填写说明：详细描述作品拟解决的实际问题，描述已存在的类似系统，并对其进行分析，作品的功能和性能需求；使用的数据集，包括数据格式，数据来源，数据获取方式，数据特点，数据规模等，并给出具体的数据样例。所提出的指标点必须等在第5章得到印证】

**2.1 问题分析**

在[1]中，Kamath等人提出了在支持向量机框架内使用多核学习的方法，并在他们的数据集上取得了50.9%的准确率。尽管该方法在当年的所有方法中取得了竞争性的结果，但是较低的准确率仍无法满足当今的使用场景。在类似的工作[3]中，Mohamad等人首次使用了深度学习技术进行参与度的研究，并**预先使用了一个面部表情识别模型来捕捉面部特征，用于初始化他们的参与度模型。**该方法在他们制作的学习参与度数据集上表现出的性能明显优于其它方法。目前来看，深度学习技术仍是最合适的学习参与度分析方法。

同时，Whitehill等人的工作[2]表明，**参与度信息主要记录在图像中**，Bosch[6]也证实了视频片段所能提供的额外信息较少。在实验中，他们使用不同长度的视频片段取得了类似的性能。[7]综述的作者声称，基于面部表情，身体姿态，EEG与ECG信息融合的多模态情感识别模型比单模态的效率更高，但是该类模型的**部署成本要大大高于单模态模型**，考虑到以上问题，本文中只对面部图像进行分析。

**2.2 数据集说明**

本研究使用的数据集如下：

**1. FER-2013：**

FER-2013是一个用于人脸表情识别的公共数据集，由35886张人脸不同表情图片组成，其中训练集28708张，验证集和测试集各3589张。该数据集由Google Search API收集，样本为48\*48像素的灰度图像。	

图像被标注为7种基本的表情类别，包括愤怒、厌恶、恐惧、快乐、中性、伤心和惊讶。该数据集的图像集中在表情强烈、清晰明确的情况下，有助于训练模型更好地区分表情。

该数据集用于模型的预训练阶段，可以提高模型对面部特征的捕捉能力。

![Aspose Words 114ca37a-2e51-44f2-8727-161185576537 002](https://github.com/Dengpc-FIRE/Student_Engagement_Dectecting_System/assets/115885750/1fe78d88-3560-4a96-ba82-cb0df1630abb)


**2. ER Dataset**

ER Dataset是我们采集并制作的，用于学习参与度识别的私有数据集。该数据集由17569张学生人脸图像组成，其中训练集14055张，验证集3514张。这些图像均由移动设备的前置摄像头拍摄，并在预处理过程中被转换为灰度图像，分辨率为48\*48像素。

在这个数据集中，图像被标注为未参与，普通参与和高度参与三个类别。实验证明，该数据集上可以训练出高性能的模型，并在实际场景中表现出了较好的准确率。

![Aspose Words 114ca37a-2e51-44f2-8727-161185576537 003](https://github.com/Dengpc-FIRE/Student_Engagement_Dectecting_System/assets/115885750/d610147f-f104-42ad-810c-ba83747fe8d0)


# 技术方案

【填写说明：从原理层面，详细介绍系统所采用的技术方案，先总体介绍，给出技术路线框架图，然后分模块详细介绍。着重介绍解决问题的思路，以及所涉及的模型、算法等；原创工作详细描述，非原创工作简略描述，并尽可能标注引用文献】

上文中提到的方法都无法完全解决我们所面临的问题，为了解决这些问题，本文提出了一种全新的技术框架（如图4所示）用于分析在线学习中学生的参与度表现。依托于该技术框架，教师可以更好地理解学生的学习状态，及时调整教学策略，提高教学效率。

![Aspose Words 114ca37a-2e51-44f2-8727-161185576537 004](https://github.com/Dengpc-FIRE/Student_Engagement_Dectecting_System/assets/115885750/b3b79db3-1693-4d88-8598-acaf2842287b)


`                          `图4. 技术路线框架图

`	`如图所示，每个学生都可以在自己的移动设备上启动一个学生端应用程序来进行本地参与度分析。由于人脸视频不需要发送到远程服务器或教师的个人电脑，这样的设计可以在保证教学质量的前提下**实现高水平的数据隐私**。摄像头获取面部图像后，最大面部区域捕获模块（Capture maximum face area）会在每7帧中找出面部区域最大的一帧。随后，该帧会被交付到轻量级神经网络中计算得到参与度分数，关于该神经网络架构的细节将在下一章进行详细介绍。

`	`考虑到参与度可能由于各种客观因素产生突变，而突变的参与度不应被用来评估学生，因此我们引入了**代表性信息处理模块**（Representative information processing module）以获得精炼参与度分数。使用精炼参与度分数的数据分析中，学习参与度的变化曲线会更加平滑，自然。

`	`教师端能够从云端数据库读取各个学生端上传的精炼参与度分数。读取到的信息在经过数据分析模块（Statistics analyze module）的处理后，最终由可视化分析模块（Visualization analysis）进行加工，以可视化图表的形式在Web页面中展示。教师端可以帮助教师更加准确地检测在线课堂中学生的参与度状态，同时突出高参与度或低参与度的时间点，以发现授课内容中枯燥困难的部分。这些数据可以量化课程的成效，提高在线课堂的教学效率。

# 方案实现

【填写说明：从工程实现的角度，详细阐述第3章提出的技术方案的具体实现过程，包括但不限于数据的采集、加工、管理、分析工具的使用，以及其中所遇到的困难，解决的方法等；所有技术实现中所引用的论文，代码，模型等内容均需要在此模块进行说明，否则评委有权利怀疑作品的原创性】

**4.1 网络模型**

本文采用了轻量级网络EfficientNet-B0[4]作为模型的backbone，并在网络中引入了轻量级的混合注意力模块（Convolutional Block Attention Module，CBAM）[5]，以平衡准确率和模型的规模,整体网络结构如图5所示。

![Aspose Words 114ca37a-2e51-44f2-8727-161185576537 005](https://github.com/Dengpc-FIRE/Student_Engagement_Dectecting_System/assets/115885750/4439c343-a129-4504-9034-0c5141cc3bf5)
![Aspose Words 114ca37a-2e51-44f2-8727-161185576537 006](https://github.com/Dengpc-FIRE/Student_Engagement_Dectecting_System/assets/115885750/23547008-a595-47ef-b5fb-be4b982e4488)

EfficientNet-B0网络的基础架构是通过神经网络架构搜索（Neural Architecture Search，NAS）得到的。该网络的核心结构为16个**移动翻转瓶颈卷积**（mobile inverted bottleneck convolution，MB Conv）模块，我们在16个MB Conv模块之后插入了混合注意力机制模块（图7）用来提炼特征。该模块能够序列化地在通道和空间两个维度上产生注意力特征图信息，然后两种特征图信息在与之前原输入特征图进行相乘进行自适应特征修正，产生最后的精炼特征图。


![Aspose Words 114ca37a-2e51-44f2-8727-161185576537 007](https://github.com/Dengpc-FIRE/Student_Engagement_Dectecting_System/assets/115885750/3c0c24a3-3c54-4018-b68d-8aa70f66b9e3)

**4.2 最大面部区域捕获模块**

为了提高系统的运算速度，我们设计了最大面部区域捕获模块对人脸图像帧进行数据筛选。该模块中使用了OpenCV的lbpcascade分类器在人脸图像帧中定位人脸区域。我们以7帧为一个处理单元，挑选出人脸区域最大的一帧，再送入参与度模型对静态图像进行参与度分类。由于人脸区域的定位速度要快于参与度模型的计算速度，该模块可以在保证分类准确率的前提下有效提升系统的运行效率。

**4.3 代表性信息处理模块**

`	`根据进化心理学，人类的心理（Mind）就是一整套信息处理的装置，这些装置是由自然选择而形成的，其目的是处理我们祖先在狩猎等生存过程中所遇到的适应问题。而对于原始社会中的人类，长时间集中在一件事情而不关注周围的变化是一件极其危险的事情，由此可见，我们的心理机制决定了我们很难保持长时间的专注。因此，当我们在评估某个学生的参与度时，应该选择其具有代表性的数据，丢弃因客观条件而导致的数据突变。基于这个想法，我们向系统中引入了**代表性信息处理模块**（Representative information processing module）。我们将连续7次的参与度数据作为一个处理单元，代表性信息处理模块会保留7次数据中样本数目最多的类别并将其余类别的数据丢弃。对于保留的参与度分数，我们将它们的平均值作为精炼参与度分数上传到云端数据库。

**4.4 ER Dataset的收集与制作**

由于人脸隐私的问题，在学习参与度检测领域中使用的数据集大都是私有数据集，无法通过开源的渠道获得。在我们的研究初期，我们曾尝试联系多个作者以获取这些私有数据集，但均未得到肯定的答复。

因此，我们构建了一个新的数据集，称为ER Dataset(Engagement Recognition Dataset)。我们的数据样本来自山东科技大学数据结构在线课程的课堂视频。在进行人脸数据采集之前，我们已经获得了所有出镜同学的批准。此外，由于参与课程的同学事先并未被告知实验，因此我们很好地规避了**霍桑效应。**

我们提取了23名同学共46个小时的视频并以固定的速率采集人脸图像样本，使我们的数据样本具有代表性，可以平均地分布在主题和时间上。之后我们对采集到的图像样本进行数据清晰，最终只保留包含人脸且面部区域清晰的样本。

我们招募了**心理学专业的本科学生来承担标注任务**，并在标注之前对他们进行了的培训。为了提高标注的准确性，每一个样本都经过了7次标注。在标注过程中，人脸图像会展示给标注人员，并被要求标注为未参与，普通参与，高度参与三个参与度等级中的一个。如果在某个样本的7个标签中相同标签个数的最大值低于5个，该样本会从ER Dataset中移除。

通过以上方法，我们创建了包含17569张已标注图像的ER Dataset,其中包括了未参与样本3041张，普通参与样本7034张，高度参与7494张。

**4.5 预训练，数据增强与损失函数**

`	`参考[3]中的经验，我们首先使用FER-2013数据集训练我们的模型从而获得了一个面部表情识别模型用于初始化我们的参与度模型。经过FER-2013数据集上的训练之后，我们的模型对面部特征拥有了更强的提取能力。随后我们将该模型在我们的ER Dataset上进行训练，相较于其它网络模型，我们的模型在参数量较小的同时取得了较好的准确率与召回率。

在训练过程中，我们尝试了多种数据增强策略，如随机水平翻转、随机擦除和随机旋转，以提高模型的泛化能力。经过消融实验验证，该方法有效地降低了数据不足的影响，并显著提高了模型的性能。

同时，为了缓解学习参与度数据集高度不平衡带来的影响，本文在训练中使用了权交叉熵损失函数，其中类别权重Wi被设置为单类别最大样本量与当前类别样本量之比，即：
Wi=CountmaxCounti

此举增加了对低样本类别的惩罚，提高了准确率和召回率，有效增强了网络模型的鲁棒性。

# 测试分析

【填写说明：通过测试与对比，论证系统的有效性，包括数据来源、数据规模、环境配置、测试过程、分析与结论等等。各参赛队务必重视数据测试，所有对自己作品准确性、有效性、稳定性，甚至作品受欢迎的程度的宣称，都应该得到数据结果或对比实验的支持，否则评审人有理由怀疑其真实性。】

**5.1 面部特征提取**

我们将模型在不同数据集上进行了预训练，效果如下：

| 网络模型                                  | 验证集准确率 |
| ----------------------------------------- | ------------ |
| EfficientNet-B0-CBAM                      | 48\.9%       |
| EfficientNet-B0-CBAM + ImageNet预训练权重 | 59\.2%       |
| EfficientNet-B0-CBAM + FER-2013预训练权重 | 63\.8%       |

观察上表可知，预训练可以为模型带来超过10%的准确率提升。在进行了ImageNet数据集的预训练后，我们的EfficientNet-B0-CBAM模型的准确率已经达到了59.2%。值得注意的是，FER-2013数据集的规模远小于ImageNet，但我们使用FER-2013数据集进行训练的权重仍然为我们带来了14.9%的准确率提升，比ImageNet数据集的提升率还要高出4.6%。这说明了捕获面部特征的能力对我们的模型至关重要。

**5.2 轻量级网络模型**

`	`我们在不同网络模型上使用了相同的训练策略，结果如下：

| 网络模型             | 验证集准确率 | 模型大小   |
| -------------------- | ------------ | ---------- |
| ResNet18             | 58\.4%       | 41\.3MB    |
| ResNet34             | **61.7%**    | **81.1MB** |
| ResNet50             | 59\.5%       | 150\.5MB   |
| ShuffleNetV2         | 57\.8%       | 18\.7MB    |
| EfficientNet-B0      | **60.1%**    | **15.5MB** |
| EfficientNet-B0-CBAM | **63.8%**    | **15.6MB** |



如上表所示，我们的backbone：EfficientNet-B0在模型大小不到ResNet34模型三分之一的情况下依然取得了相近的性能。在我们向E EfficientNet-B0中加入了CBAM后，验证集准确率已经超过了ResNet34在该数据集上的表现。同时，由于CBAM的轻量级，我们的模型只增加了0.1MB，几乎可以忽略不计。

实验证明，我们的网络结构在保证模型轻量化的前提下，仍然能够取得竞争性的结果。

**5.3数据增强**

`	`在选择数据增强策略时，我们进行了大量的消融实验：



| 数据增强策略                   | 验证集准确率 |
| ------------------------------ | ------------ |
| 无                             | 55\.4%       |
| 随机水平翻转                   | 55\.8%       |
| 随机旋转                       | 58\.1%       |
| 随机擦除                       | 57\.8%       |
| 中心裁剪                       | 60\.6%       |
| 随机旋转 + 随机擦除            | 60\.3%       |
| 随机旋转 + 随机擦除 + 中心裁剪 | 63\.8%       |




实验结果表明，在我们的数据集上，随机旋转技术能够带来2.7%的准确率提升，而随机擦除技术则能够带来2.4%的提升。然而，最有效的技术是中心裁剪，它能够带来5.2%的准确率提升。相比之下，随机水平翻转的准确率提升只有0.4%，**这可能是由于样本特性导致的。**具体来说，我们的数据集中的人脸图像具有较高的对称性，因此随机水平翻转的意义不大。相反，由于人脸通常处于样本图像的中心位置，中心裁剪可以消除环境噪音并提高模型对面部区域的关注度，因此能够带来如此大的准确率提升。

**5.4 实际场景分类效果测试**

`	`我们邀请了23位志愿者，在教室，宿舍，图书馆等不同环境下对参与度分析效果进行测试，并在测试后进行满意度调查。

闭眼.jpg

趴下睡觉.jpg

向左看.jpg

向右看.jpg

精神不振.jpg

普通参与.jpg

高度参与.jpg

实验结果表明，我们的系统能够准确捕捉多种低参与度行为，例如闭眼、趴下睡觉、左右张望以及精神不振等。同时，只要保证光照条件能够使面部区域清晰突出，使用者所处的环境对我们的模型的影响可以忽略不计。在实验过程中，只有一位志愿者由于面部光线过暗而一直得到低参与度的分数，但是剩余的22位志愿者都给予了我们积极的反馈。基于这些反馈结果，在满意度调查中，我们最终取得了95.6%的满意率。

# 部署推广

【填写说明：该作品如何部署并投入实用？描述使用、推广方法等，以及使用中要注意的问题。如作品已经进入实用阶段，亦在此说明】

**6.1 使用方法**

**6.1.1 独立软件安装方式**

对于一些中小学或者高校，没有现存的独立的线上教学平台，只是简单搭建临时用的平台或者简单依附于其他线上教育平台，那么可以选择独立软件安装的方式，即让用户下载并安装我们的应用。这样可以保证我们的应用具有较高的独立性和自主性，可以更加自由地开发和升级功能。

**6.1.2 嵌入相关平台**

对于比较成熟的教育平台，例如作业帮、新东方、学习通和智慧树等，将我们的项目嵌入到平台的软件里，这样用户可以在平台内直接使用我们的应用，无需额外安装和登录。这种方式可以提高用户体验和应用的曝光率。具体实现方式可以根据平台的要求来选择，例如使用Web API接口、SDK、插件等方式。后期针对不同用户群体的不同平台的特点和需求，我们会进行界面设计、交互优化、数据可视化等方面的优化，提高用户体验和用户黏性。

**6.2 推广方法**

**6.2.1 中小学、高校试点**

我们计划在需要线上教学的中小学、高校以及因其他限制需要通过线上授课的海外高校等提供免费试点。并在试点过程中对项目的效果和使用情况进行监测和记录。试点学校将免费获得我们的软件和技术支持。我们将通过用户满意度、项目使用数据和反馈等指标来评估项目的效果和优化方向。将针对试点学校和学生的反馈进行改进，以提高我们的项目在实际应用中的效果和可行性。

**6.2.2线上教育平台合作**

向北京作业帮线上学科培训的“一课”学习平台、“猿辅导”在线教育、“新东方”教育平台、中国大学MOOC、超星学习通及知到智慧树等平台提供我们的项目信息和数据，包括项目的简介、特点、功能、技术细节和效果等方面的信息。与平台协商合作方式，包括合作内容、合作方式、合作费用等方面的细节，以及相关的合作协议和合同。在与平台达成合作后，在平台上推广我们的项目，例如在智慧树开发一个插件或模块。作为单独的学生参与度检测模块服务方赋能各个平台。

**6.2.3 联系政府教育部门**

《中共中央关于制定国民经济和社会发展第十四个五年规划和二〇三五年远景目标的建议》中提到：“深化教育改革，推进素质教育，坚持德育为先，实现教育公平和质量共赢；发挥科技创新引领作用，提升经济高质量发展水平。”我们针对学生在线教育领域的现状和问题，提出相应的政策建议，融入此轻量级的，带有隐私保护功能的学生参与度分析系统，从而引起政府相关教育部门的重视，并为我们项目的推广提供有力支持，带来积极的教育变革。

**6.3 实际使用中注意问题**

**6.3.1 数据隐私保护**

学生上传的数据涉及到隐私问题，需要保证数据的安全性和保密性，防止数据泄露。在数据传输的过程中，需要对学生的参与度信息进行加密，防止数据被窃取或泄漏。可以使用常见的加密算法，如AES、RSA等算法，对数据进行加密。对于数据的访问和使用，需要进行访问控制，只有具备相应权限的人员才能够访问和使用数据。可以采用RBAC等权限控制技术，对数据进行权限管理。

**6.3.1 用户体验优化**

我们从用户的角度出发，优化前端界面和使用流程，提高用户的满意度和使用体验。采用可视化技术，如图表、柱状图等方式来展示数据，使用户可以直观地了解检测结果和参与度等信息。



# 作品总结

【填写说明：从创意、技术路线、工作量、数据和测试效果等方面对作品进行自我评价和总结，并对作品的进一步提升和应用拓展提出展望】

虽然目前存在许多参与度检测技术，但是这些技术在线上课堂中的应用依旧非常有限。在实际的线上课堂中，大多数学生由于隐私问题不愿意分享自己的面部视频。即使学生被要求强制开启摄像头，让教师通过每个人的面部视频来分析整个班级的课堂参与度仍然是一项困难的工作。为了解决这个问题，**本文提出了一种轻量级的，带有隐私保护功能的学生参与度分析技术框架。该框架可以整合到现有的在线学习平台（例如超星学习通，知到智慧树等），快速准确地评估学生的参与度。**学生只需要开启摄像头，教师们就可以在平台教师端上获取整个班级的参与度信息。为了保护学生的隐私，所有的面部视频信息都将在学生设备上进行处理，老师只能得到对应的分析结果。由于模型计算量相对较小，因此即使是在性能比较落后的移动设备上，我们的系统也可以高效运行。

由于该领域公开数据集的缺失，**我们构建了自己的数据集**（ER Dataset）。。该数据集由具有心理学专业知识的标注人员标记，我们希望这个数据集将有助于从视觉数据进行参与度识别的研究。

此外，**我们提出了一种全新的网络架构**，并在众多网络中取得了竞争性的效果。在构建参与度模型时，我们首先使用面部表情数据对模型进行预训练，然后在其权重基础上生成了一个用于学习参与度分类的模型。在训练过程中，我们使用了加权交叉熵损失，并通过大量消融实验选出了效果较好的多种数据增强策略。我们已经对一系列基准模型进行了评估，以证明该模型的有效性。结果表明，相较于使用所有标准评估指标的基准模型，该模型带来了显著的改进。

在未来，我们有必要**使用额外的数据**来提高参与度分类模型的性能。由于目前可用的数据集规模较小，这一方法受到了限制。另外，我们认为在保证模型轻量级的前提下引入**多模态的特征**有助于改进模型的分类效果。引入的特征信息不一定由额外的设备实时检测获得，也可以在用户的先验知识（例如个性，年龄，教育背景等）中提取。最后，我们期待该系统可以为教师和学生之间的互动提供更多的可能，以帮助教师获得更好的授课体验。

# 参考文献

1. Kamath A, Biswas A, Balasubramanian V. A crowdsourced approach to student engagement recognition in e-learning environments[C]//2016 IEEE Winter Conference on Applications of Computer Vision (WACV). IEEE, 2016: 1-9.
1. Whitehill J, Serpell Z, Lin Y C, et al. The faces of engagement: Automatic recognition of student engagementfrom facial expressions[J]. IEEE Transactions on Affective Computing, 2014, 5(1): 86-98.
1. Mohamad Nezami O, Dras M, Hamey L, et al. Automatic recognition of student engagement using deep learning and facial expression[C]//Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, Cham, 2020: 273-289.
1. Tan M, Le Q. Efficientnet: Rethinking model scaling for convolutional neural networks[C]//International conference on machine learning. PMLR, 2019: 6105-6114.
1. Woo S, Park J, Lee J Y, et al. Cbam: Convolutional block attention module[C]//Proceedings of the European conference on computer vision (ECCV). 2018: 3-19.
1. Bosch, N., et al.: Automatic detection of learning-centered affective states in the wild. In: IUI, pp. 379–388. ACM (2015)
1. M. Imani and G. A. Montazer, “A survey of emotion recognition methods with emphasis on e-learning environments,” Journal of Network and Computer Applications, vol. 147, p. 102423, 2019.
   ．2．

